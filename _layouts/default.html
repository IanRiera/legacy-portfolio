<!DOCTYPE html>
<html>
  <head>
    <title>{% if page.title %}{{ page.title }} – {% endif %}{{ site.name }} – {{ site.description }}</title>

    {% include meta.html %}

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
    <link rel="alternate" type="application/rss+xml" title="{{ site.name }} - {{ site.description }}" href="{{ site.baseurl }}/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="{{ site.baseurl }}/" class="site-avatar"><img src="{{ site.avatar }}" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="{{ site.baseurl }}/">{{ site.name }}</a></h1>
            <p class="site-description">{{ site.description }}</p>
          </div>

          <nav>
            <a href="{{ site.baseurl }}/about">About me</a>
            <a href="{{ site.baseurl }}/">Blog</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
       <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h3>
                Hello world, I am Ian!
              </h3>
              <p>I am a Telecommunication engineer and Master's student in Computer Vision at UAB (Universitat Autònoma de Barcelona), in a <a href="https://pagines.uab.cat/mcv/">program</a> that has been designed jointly with UPC (Universitat Politècnica de Catalunya), UPF (Universitat Pompeu Fabra) and UOC (Universitat Oberta de Catalunya). 
                I am currently completing my Master Thesis as an internship at <a href="https://beamagine.com/">Beamagine S.L.</a> in collaboration with the <a href="https://imatge.upc.edu/web/">Image Processing Group</a> from UPC. The thesis focuses on pedestrian detection on point clouds obtained with the company's Lidar.
              </p>
              <p>
                ...
              </p>
              <p>
                ...
              </p>
              
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I am interested in computer vision, machine learning, image processing and data science. Here I present a few projects completed during the Master in Computer Vision.
              </p>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tr>
                  <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
                    <img src="{{site.baseurl}}/images/video_surveillance.png" alt="video_surveillance_png"
                      style="width:auto; height:auto; max-width:100%;" >
                  </td>
                  <td style="padding:2.5%;width:75%;vertical-align:middle">
                      <papertitle><strong>Video Surveillance for Road Traffic Monitoring</strong></papertitle>
                    </a>
                    <br>
                    Pol Albacar, 
                    <a href="https://oscarlorente.github.io/">Òscar Lorente</a>,
                    <a href="https://eddiemg.github.io/">Eduard Mainou</a>, 
                    <strong>Ian Riera</strong>
                    <br>
                    <em>arXiv</em>, 2021
                    <br>
                    <a href="https://arxiv.org/abs/2105.04908">arXiv</a> /
                    <a href="https://github.com/IanRiera/MCV-M6-Video-Traffic-Monitoring">code</a>
                    <p>
                      Solution to the third track of the <a href="https://www.aicitychallenge.org/">AI-City Challenge</a>, that aims to track vehicles across multiple cameras placed in multiple intersections spread out over a city. The methodology followed focuses first in solving multi-tracking in a single camera and then extending it to multiple cameras using siamese networks and metric learning.
                    </p>
                  </td>
                </tr>
              </table>
  
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tr>
                  <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
                    <img src="{{site.baseurl}}/images/3D_reconstruction_urban_scenes.png" alt="3D_reconstruction_urban_scenes_png"
                      style="width:auto; height:auto; max-width:100%;" >
                  </td>
                  <td style="padding:2.5%;width:75%;vertical-align:middle">
                      <papertitle><strong>3D Reconstruction of Urban Scenes</strong></papertitle>
                    </a>
                    <br>
                    Josep Brugués,
                    <a href="https://oscarlorente.github.io/">Òscar Lorente</a>,
                    <strong>Ian Riera</strong>,
                    Sergi García
                    <br>
                    2021
                    <br>
                    <a href="https://github.com/IanRiera/MCV-M4-3D-Vision">code</a> /
                    <a href="{{site.baseurl}}/pdfs/3D-reconstruction-urban-scenes.pdf">slides</a>
                    <p>
                      3D reconstruction of buildings from a set of images taken from different points of view (frontal images of the façades and aerial images). Rectify the perspective distortion from a single view, estimate essential and fundamental matrix, calibrate a camera with a planar pattern, estimate the depth of points in the scene given two images, generate new views of the scene, and compute a 3D model either from a set of calibrated or uncalibrated cameras (SfM).
                    </p>
                  </td>
                </tr>
              </table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tr>
                  <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
                    <img src="{{site.baseurl}}/images/scene_understanding.png" alt="scene_understanding_png"
                      style="width:auto; height:auto; max-width:100%;" >
                  </td>
                  <td style="padding:2.5%;width:75%;vertical-align:middle">
                      <papertitle><strong>Scene Understanding for Autonomous Driving</strong></papertitle>
                    </a>
                    <br>
                    <a href="https://oscarlorente.github.io/">Òscar Lorente</a>, 
                    <strong>Ian Riera</strong>, 
                    <a href="https://adityassrana.github.io/blog/about">Aditya Rana</a>
                    <br>
                    <em>arXiv</em>, 2021
                    <br>
                    <a href="https://arxiv.org/abs/2105.04905">arXiv</a> /
                    <a href="https://github.com/IanRiera/MCV-M5-Object-Detection-and-Segmentation">code</a>
                    <p>
                      Study of the behaviour of different configurations of RetinaNet, Faster R-CNN and Mask R-CNN (Detectron2) by a qualitative and quantitative evaluation on KITTI-MOTS, MOTSChallenge and out of context datasets.
                    </p>
                  </td>
                </tr>
              </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tr>
                  <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
                    <img src="{{site.baseurl}}/images/image_classification.png" alt="image_classification_png"
                      style="width:auto; height:auto; max-width:100%;" >
                  </td>
                  <td style="padding:2.5%;width:75%;vertical-align:middle">
                      <papertitle><strong>Image Classification with Classic and Deep Learning Techniques</strong></papertitle>
                    </a>
                    <br>
                    <a href="https://oscarlorente.github.io/">Òscar Lorente</a>, 
                    <strong>Ian Riera</strong>, 
                    <a href="https://adityassrana.github.io/blog/about">Aditya Rana</a>
                    <br>
                    <em>arXiv</em>, 2021
                    <br>
                    <a href="https://arxiv.org/abs/2105.04895">arXiv</a> /
                    <a href="https://github.com/IanRiera/MCV-M3-Machine-Learning-for-Computer-Vision">code</a>
                    <p>
                      Image classifier using both classic computer vision techniques (Bag of Visual Words classifier using SVM) and deep learning techniques (MLPs, InceptionV3 and our own CNN: TinyNet).
                    </p>
                  </td>
                </tr>
              </table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tr>
                  <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
                    <img src="{{site.baseurl}}/images/museum_painting_retrieval.png" alt="museum_painting_retrieval_png"
                      style="width:auto; height:auto; max-width:100%;" >
                  </td>
                  <td style="padding:2.5%;width:75%;vertical-align:middle">
                      <papertitle><strong>Museum Painting Retrieval</strong></papertitle>
                    </a>
                    <br>
                    <a href="https://oscarlorente.github.io/">Òscar Lorente</a>, 
                    <strong>Ian Riera</strong>, 
                    Shauryadeep Chaudhuri, 
                    Oriol Catalan, 
                    Víctor Casales 
                    <br>
                    <em>arXiv</em>, 2021
                    <br>
                    <a href="https://arxiv.org/abs/2105.04891">arXiv</a> /
                    <a href="https://github.com/oscarlorente/Museum-Painting-Retrieval">code</a>
                    <p>
                      Query by example CBIR system for finding paintings in a museum image collection using color, texture, text and feature descriptors in datasets with different perturbations in the images: noise, overlapping text boxes, color corruption and rotation.
                    </p>
                  </td>
                </tr>
              </table>
        
            

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          {% include svg-icons.html %}
        </footer>
      </div>
    </div>

    {% include analytics.html %}
  </body>
</html>
